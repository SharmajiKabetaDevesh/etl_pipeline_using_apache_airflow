In the world of data engineering, building an efficient ETL (Extract, Transform, Load) pipeline is crucial for transforming raw data into actionable insights. 
An ETL pipeline automates the flow of data from various sources, processes it based on business needs, and loads it into a destination for analysis or reporting. 
The complexity of the process often requires careful planning and design. 
The data was extracted from nasa public api and then after a simple transformation I saved it in an Postgres Database.


![etlpipeline_page-0001](https://github.com/user-attachments/assets/6d026d44-2860-4fcc-bcb4-8897f44500de)
![Screenshot (448)](https://github.com/user-attachments/assets/df4b43dc-2a5b-4cf5-a182-8edc0ad77bbc)
![Screenshot (449)](https://github.com/user-attachments/assets/d99dce14-8c9a-4a68-8f5c-a2c7e23eedf7)
![Screenshot (450)](https://github.com/user-attachments/assets/56992833-e78a-4cad-be37-4ddbf9dabf8f)
![Screenshot (451)](https://github.com/user-attachments/assets/800df243-143c-4d29-862b-53048532ef6f)

